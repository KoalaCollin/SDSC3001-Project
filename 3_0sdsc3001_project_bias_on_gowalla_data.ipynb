{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "UYkr4dj-08zO",
    "outputId": "69975e32-74fc-4d7e-e78f-d1669852ec58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Constants\n",
    "D_MAX = 110           # Maximum distance for co-location (meters)\n",
    "P_INF = 0.1           # Infection probability\n",
    "TIME_WINDOW = 3600    # Time window for co-location (seconds)\n",
    "INITIAL_INFECTED = 0.01  # Initial fraction of infected nodes\n",
    "SAMPLING_PROPORTIONS = np.array([0.025, 0.05, 0.1, 0.2])  # Sampling proportions (0.025, 0.05, 0.1, 0.2)\n",
    "\n",
    "# STEP 1: Load the Gowalla dataset\n",
    "file_path = 'loc-gowalla_totalCheckins.txt/Gowalla_totalCheckins.txt'  # Replace with your dataset path\n",
    "\n",
    "# Define column names based on Gowalla dataset format\n",
    "columns = ['user_id', 'timestamp', 'latitude', 'longitude', 'location_id']\n",
    "\n",
    "# Load the dataset\n",
    "gowalla_data = pd.read_csv(file_path, sep='\\t', names=columns, parse_dates=['timestamp'])\n",
    "print(\"Dataset Loaded Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6uYy6WdIaUDq"
   },
   "outputs": [],
   "source": [
    "days_to_keep = 25\n",
    "# 指定起始日期\n",
    "start_date = pd.Timestamp('2010-05-22 02:49:04+00:00')\n",
    "\n",
    "# 往后读取25天的数据\n",
    "end_date = start_date + pd.DateOffset(days=days_to_keep)\n",
    "gowalla_data = gowalla_data[gowalla_data['timestamp'] >= start_date]\n",
    "gowalla_data = gowalla_data[gowalla_data['timestamp'] <= end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VHN0dt7G08zX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact Graph Generated Successfully!\n"
     ]
    }
   ],
   "source": [
    "def build_contact_network_optimized(data, d_max=D_MAX, time_window=TIME_WINDOW):\n",
    "    \"\"\"\n",
    "    Build a co-location graph using spatial and temporal optimizations.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Sort data by timestamp for efficient grouping\n",
    "    data = data.sort_values(by='timestamp')\n",
    "\n",
    "    # Group data into time windows\n",
    "    min_time = data['timestamp'].min()\n",
    "    data['time_bucket'] = ((data['timestamp'] - min_time).dt.total_seconds() // time_window).astype(int)\n",
    "    grouped = data.groupby('time_bucket')\n",
    "\n",
    "    # Process each time bucket\n",
    "    for _, group in grouped:\n",
    "        # Create a KDTree for spatial indexing within the current time window\n",
    "        coords = group[['latitude', 'longitude']].values\n",
    "        user_ids = group['user_id'].values\n",
    "        tree = cKDTree(coords)\n",
    "\n",
    "        # Find all pairs of users within the distance threshold\n",
    "        pairs = tree.query_pairs(d_max / 1000)  # Convert meters to kilometers for KDTree\n",
    "        for i, j in pairs:\n",
    "            user1, user2 = user_ids[i], user_ids[j]\n",
    "            G.add_edge(user1, user2)\n",
    "\n",
    "    return G\n",
    "contact_graph = build_contact_network_optimized(gowalla_data)\n",
    "print(\"Contact Graph Generated Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jBiMmNkV08zY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Simulated Successfully!\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Simulate the ground truth spread\n",
    "def simulate_ground_truth(G, p_inf, initial_infected=INITIAL_INFECTED):\n",
    "    \"\"\"Simulate SIR model for the ground truth.\"\"\"\n",
    "    infected = set(np.random.choice(list(G.nodes), int(len(G) * initial_infected), replace=False))\n",
    "    susceptible = set(G.nodes) - infected\n",
    "    true_spread = []\n",
    "\n",
    "    while susceptible:\n",
    "        new_infected = set()\n",
    "        for u in susceptible:\n",
    "            neighbors = set(G.neighbors(u))\n",
    "            if any(np.random.rand() < p_inf for v in neighbors if v in infected):\n",
    "                new_infected.add(u)\n",
    "        if not new_infected:\n",
    "            break\n",
    "        infected |= new_infected\n",
    "        susceptible -= new_infected\n",
    "        true_spread.append(len(infected))\n",
    "    return true_spread\n",
    "\n",
    "true_spread = simulate_ground_truth(contact_graph, P_INF)\n",
    "print(\"Ground Truth Simulated Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VGovjIUg08zZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish scaling method\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Implement the five methods\n",
    "def scaling_method(sub_sample, total_population, p_s):\n",
    "    \"\"\"Simple scaling method.\"\"\"\n",
    "    return [len(sub_sample) / p_s for _ in range(len(total_population))]\n",
    "\n",
    "print(\"finish scaling method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6wtVMONk08za"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish location modeling\n"
     ]
    }
   ],
   "source": [
    "def location_modeling(contact_graph, p_inf, p_s, d_max):\n",
    "    \"\"\"Density-Based Location Modeling method.\"\"\"\n",
    "    infected_counts = []\n",
    "    sampled_nodes = set(np.random.choice(list(contact_graph.nodes), int(len(contact_graph) * p_s), replace=False))\n",
    "    observed_contacts = defaultdict(int)\n",
    "\n",
    "    # Count contacts within sampled nodes\n",
    "    for u in sampled_nodes:\n",
    "        for v in contact_graph.neighbors(u):\n",
    "            if v in sampled_nodes:\n",
    "                observed_contacts[u] += 1\n",
    "\n",
    "    # Estimate density and scale to the full population\n",
    "    for _ in range(len(contact_graph)):\n",
    "        estimated_infections = sum(p_inf * (count / p_s) for count in observed_contacts.values())\n",
    "        infected_counts.append(estimated_infections)\n",
    "    return infected_counts\n",
    "\n",
    "print(\"finish location modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yDKOUvHP08zb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish poll-spreader\n"
     ]
    }
   ],
   "source": [
    "def poll_spreader(contact_graph, p_inf, initial_infected=INITIAL_INFECTED):\n",
    "    \"\"\"PollSpreader method.\"\"\"\n",
    "    infected = set(np.random.choice(list(contact_graph.nodes), int(len(contact_graph) * initial_infected), replace=False))\n",
    "    infected_counts = []\n",
    "\n",
    "    # Simulate first-hop infections\n",
    "    for _ in range(len(contact_graph)):\n",
    "        new_infected = set()\n",
    "        for u in infected:\n",
    "            for v in contact_graph.neighbors(u):\n",
    "                if v not in infected and np.random.rand() < p_inf:\n",
    "                    new_infected.add(v)\n",
    "        infected.update(new_infected)\n",
    "        infected_counts.append(len(infected))\n",
    "    return infected_counts\n",
    "\n",
    "print(\"finish poll-spreader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wZfScv_q08zc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish poll-susceptible upper\n"
     ]
    }
   ],
   "source": [
    "def poll_susceptible_upper(contact_graph, p_inf):\n",
    "    \"\"\"PollSusceptible Upper Bound method.\"\"\"\n",
    "    infected_counts = []\n",
    "    susceptible = set(contact_graph.nodes)\n",
    "    infected = set(np.random.choice(list(contact_graph.nodes), int(len(contact_graph) * 0.01), replace=False))\n",
    "\n",
    "    # Upper bound assumption: every susceptible node gets infected by at least one neighbor\n",
    "    for _ in range(len(contact_graph)):\n",
    "        new_infected = set()\n",
    "        for u in susceptible:\n",
    "            for v in contact_graph.neighbors(u):\n",
    "                if v in infected:\n",
    "                    new_infected.add(u)\n",
    "                    break\n",
    "        infected.update(new_infected)\n",
    "        susceptible -= new_infected\n",
    "        infected_counts.append(len(infected))\n",
    "    return infected_counts\n",
    "\n",
    "print(\"finish poll-susceptible upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h9angPU108zd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish poll-susceptile lower\n"
     ]
    }
   ],
   "source": [
    "def poll_susceptible_lower(contact_graph, p_inf):\n",
    "    \"\"\"PollSusceptible Lower Bound method.\"\"\"\n",
    "    infected_counts = []\n",
    "    susceptible = set(contact_graph.nodes)\n",
    "    infected = set(np.random.choice(list(contact_graph.nodes), int(len(contact_graph) * 0.01), replace=False))\n",
    "\n",
    "    # Lower bound assumption: minimal independent paths contribute to infections\n",
    "    for _ in range(len(contact_graph)):\n",
    "        new_infected = set()\n",
    "        for u in susceptible:\n",
    "            infected_neighbors = [v for v in contact_graph.neighbors(u) if v in infected]\n",
    "            if infected_neighbors and np.random.rand() < p_inf:\n",
    "                new_infected.add(u)\n",
    "        infected.update(new_infected)\n",
    "        susceptible -= new_infected\n",
    "        infected_counts.append(len(infected))\n",
    "    return infected_counts\n",
    "\n",
    "print(\"finish poll-susceptile lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOLXqVn108ze"
   },
   "outputs": [],
   "source": [
    "# STEP 5: Evaluate bias for each sampling proportion\n",
    "method_biases = {method: [] for method in [\"Scaling\", \"Location Modeling\", \"PollSpreader\",\n",
    "                                           \"PollSusceptible Upper\", \"PollSusceptible Lower\"]}\n",
    "\n",
    "# Iterate over sampling proportions\n",
    "for p_s in SAMPLING_PROPORTIONS:\n",
    "    sub_sample = set(np.random.choice(list(contact_graph.nodes), int(len(contact_graph) * p_s), replace=False))\n",
    "    scaling_results = scaling_method(sub_sample, list(contact_graph.nodes), p_s)\n",
    "    location_modeling_results = location_modeling(contact_graph, P_INF, p_s, D_MAX)\n",
    "    poll_spreader_results = poll_spreader(contact_graph, P_INF)\n",
    "    poll_susceptible_upper_results = poll_susceptible_upper(contact_graph, P_INF)\n",
    "    poll_susceptible_lower_results = poll_susceptible_lower(contact_graph, P_INF)\n",
    "\n",
    "    # Calculate bias for each method\n",
    "    method_biases[\"Scaling\"].append(np.mean([(est - true) / true for est, true in zip(scaling_results, true_spread)]))\n",
    "    method_biases[\"Location Modeling\"].append(np.mean([(est - true) / true for est, true in zip(location_modeling_results, true_spread)]))\n",
    "    method_biases[\"PollSpreader\"].append(np.mean([(est - true) / true for est, true in zip(poll_spreader_results, true_spread)]))\n",
    "    method_biases[\"PollSusceptible Upper\"].append(np.mean([(est - true) / true for est, true in zip(poll_susceptible_upper_results, true_spread)]))\n",
    "    method_biases[\"PollSusceptible Lower\"].append(np.mean([(est - true) / true for est, true in zip(poll_susceptible_lower_results, true_spread)]))\n",
    "print(\"finish methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 6: Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for method, biases in method_biases.items():\n",
    "    plt.plot(SAMPLING_PROPORTIONS, biases, label=method)\n",
    "\n",
    "plt.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.xlabel(\"Sample Proportion (\\(p_s\\))\")\n",
    "plt.ylabel(\"Bias\")\n",
    "plt.title(\"Bias on Gowalla Dataset (Figure 13)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6096180,
     "sourceId": 9919431,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6097282,
     "sourceId": 9921021,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
